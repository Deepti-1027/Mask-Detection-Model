{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rA34stAJWGDc"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from sklearn import *\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QFDLV7zYWSoX"
   },
   "source": [
    "# New Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "hRrUCGaoWGDo",
    "outputId": "7f49fffc-c17f-4134-e180-7eb9af9c28d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "#!unzip -uq \"/content/drive/My Drive/Colab Notebooks/dataset.zip\" -d \"/content/drive/My Drive/Colab Notebooks/dataset\"\n",
    "Directory=r\"/content/drive/My Drive/Colab Notebooks/dataset/\"\n",
    "Category=[\"with_mask\",\"without_mask\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "nrcEko-pWGDw",
    "outputId": "fc131266-a6a5-4177-a82b-0d3bd594ec5c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    }
   ],
   "source": [
    "#grab the list of images\n",
    "\n",
    "data=[]\n",
    "category=[]\n",
    "\n",
    "\n",
    "for cat in Category:\n",
    "    path=os.path.join(Directory,cat)\n",
    "    for p in os.listdir(path):\n",
    "        img_path=os.path.join(path,p)\n",
    "        image=load_img(img_path,target_size=(224,224))\n",
    "        image=img_to_array(image)\n",
    "        image=preprocess_input(image)\n",
    "        \n",
    "        data.append(image)\n",
    "        category.append(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "phVcsSxIWGD3"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "#lb=LabelBinarizer()\n",
    "lb = LabelBinarizer()\n",
    "category=lb.fit_transform(category)\n",
    "category=to_categorical(category)\n",
    "\n",
    "\n",
    "## we have list of both data as well as for labels\n",
    "\n",
    "## labels ----> categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Uz7lq9X-WGD-"
   },
   "outputs": [],
   "source": [
    "data=np.array(data,dtype=\"float32\")\n",
    "category=np.array(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pJz7a5HyWGEF"
   },
   "outputs": [],
   "source": [
    "trainx,testx,trainy,testy=train_test_split(data,category,test_size=0.20,stratify=category,random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PgyJ62CLWGEK"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Input,Flatten,Dropout,Conv2D,AveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rwW9Q4wyegfr"
   },
   "outputs": [],
   "source": [
    "aug=ImageDataGenerator(rotation_range=20,\n",
    "                       width_shift_range=0.20,\n",
    "                       height_shift_range=0.20,\n",
    "                       zoom_range=.15,\n",
    "                       shear_range=0.15,\n",
    "                       horizontal_flip=True,\n",
    "                       fill_mode='nearest'\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 92
    },
    "colab_type": "code",
    "id": "mo5tUerkfQpQ",
    "outputId": "b52e6f4d-4e69-4a92-b646-dfc739e58d6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "9412608/9406464 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "baseModel=MobileNetV2(weights='imagenet',\n",
    "                      include_top=False,\n",
    "                      input_tensor=Input(shape=(224,224,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2dv4gXVDf3tx"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense\n",
    "headModel=baseModel.output\n",
    "headModel=AveragePooling2D(pool_size=(7,7))(headModel)\n",
    "headModel=Flatten(name='flatten')(headModel)\n",
    "headModel=Dense(128,activation='relu')(headModel)\n",
    "headModel=Dropout(0.5)(headModel)\n",
    "headModel=Dense(2,activation='softmax')(headModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jx465Nurmuhk"
   },
   "outputs": [],
   "source": [
    "## now place this FC on the top of baseModel\n",
    "\n",
    "model=Model(inputs=baseModel.input,outputs=headModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sjIyA2iFnHLY"
   },
   "outputs": [],
   "source": [
    "for layer in baseModel.layers:\n",
    "  layer.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iTpUMNSLnhNR"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"Adam\",loss=\"binary_crossentropy\",metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 770
    },
    "colab_type": "code",
    "id": "TuBHpXf5oCM8",
    "outputId": "bf402e96-a10e-471a-d379-211276e44915"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "54/54 [==============================] - 84s 2s/step - loss: 0.0980 - accuracy: 0.9678 - val_loss: 0.0377 - val_accuracy: 0.9885\n",
      "Epoch 2/20\n",
      "54/54 [==============================] - 83s 2s/step - loss: 0.0332 - accuracy: 0.9901 - val_loss: 0.0556 - val_accuracy: 0.9862\n",
      "Epoch 3/20\n",
      "54/54 [==============================] - 83s 2s/step - loss: 0.0208 - accuracy: 0.9901 - val_loss: 0.0608 - val_accuracy: 0.9885\n",
      "Epoch 4/20\n",
      "54/54 [==============================] - 83s 2s/step - loss: 0.0170 - accuracy: 0.9947 - val_loss: 0.0464 - val_accuracy: 0.9862\n",
      "Epoch 5/20\n",
      "54/54 [==============================] - 83s 2s/step - loss: 0.0213 - accuracy: 0.9918 - val_loss: 0.0416 - val_accuracy: 0.9885\n",
      "Epoch 6/20\n",
      "54/54 [==============================] - 86s 2s/step - loss: 0.0205 - accuracy: 0.9936 - val_loss: 0.0290 - val_accuracy: 0.9931\n",
      "Epoch 7/20\n",
      "54/54 [==============================] - 84s 2s/step - loss: 0.0141 - accuracy: 0.9965 - val_loss: 0.0374 - val_accuracy: 0.9862\n",
      "Epoch 8/20\n",
      "54/54 [==============================] - 83s 2s/step - loss: 0.0154 - accuracy: 0.9947 - val_loss: 0.0297 - val_accuracy: 0.9908\n",
      "Epoch 9/20\n",
      "54/54 [==============================] - 83s 2s/step - loss: 0.0138 - accuracy: 0.9953 - val_loss: 0.0778 - val_accuracy: 0.9817\n",
      "Epoch 10/20\n",
      "54/54 [==============================] - 83s 2s/step - loss: 0.0138 - accuracy: 0.9965 - val_loss: 0.0356 - val_accuracy: 0.9931\n",
      "Epoch 11/20\n",
      "54/54 [==============================] - 83s 2s/step - loss: 0.0131 - accuracy: 0.9959 - val_loss: 0.0298 - val_accuracy: 0.9931\n",
      "Epoch 12/20\n",
      "54/54 [==============================] - 83s 2s/step - loss: 0.0151 - accuracy: 0.9959 - val_loss: 0.0478 - val_accuracy: 0.9862\n",
      "Epoch 13/20\n",
      "54/54 [==============================] - 86s 2s/step - loss: 0.0113 - accuracy: 0.9953 - val_loss: 0.0477 - val_accuracy: 0.9862\n",
      "Epoch 14/20\n",
      "54/54 [==============================] - 83s 2s/step - loss: 0.0110 - accuracy: 0.9953 - val_loss: 0.0373 - val_accuracy: 0.9908\n",
      "Epoch 15/20\n",
      "54/54 [==============================] - 83s 2s/step - loss: 0.0103 - accuracy: 0.9965 - val_loss: 0.0735 - val_accuracy: 0.9908\n",
      "Epoch 16/20\n",
      "54/54 [==============================] - 83s 2s/step - loss: 0.0162 - accuracy: 0.9953 - val_loss: 0.0898 - val_accuracy: 0.9817\n",
      "Epoch 17/20\n",
      "54/54 [==============================] - 83s 2s/step - loss: 0.0124 - accuracy: 0.9971 - val_loss: 0.0597 - val_accuracy: 0.9885\n",
      "Epoch 18/20\n",
      "54/54 [==============================] - 83s 2s/step - loss: 0.0051 - accuracy: 0.9988 - val_loss: 0.0409 - val_accuracy: 0.9862\n",
      "Epoch 19/20\n",
      "54/54 [==============================] - 84s 2s/step - loss: 0.0096 - accuracy: 0.9965 - val_loss: 0.0483 - val_accuracy: 0.9862\n",
      "Epoch 20/20\n",
      "54/54 [==============================] - 87s 2s/step - loss: 0.0050 - accuracy: 0.9982 - val_loss: 0.0579 - val_accuracy: 0.9862\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f682faf9550>"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(aug.flow(trainx,trainy,batch_size=32),steps_per_epoch=len(trainx)//32,validation_data=(testx,testy),validation_steps=len(testx)//32,epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dmVtT72posCW"
   },
   "outputs": [],
   "source": [
    "model.save(\"mask_detector.model\",save_format=\"h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rzIgtKBFt75u"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "MaskDetection.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
